{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Review Classification\n",
    "\n",
    "Here we show how a computer can tell apart good and bad movie reviews. To do so, we create a \"classifier\": A device that learns data categorization patterns from a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we get a lot of movie reviews and label them as good or bad. We will use these real reviews to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SETUP MAGIC\n",
    "f = open(\"train.tsv\")\n",
    "cur = -1\n",
    "all_X = []\n",
    "all_y = []\n",
    "for line in f:\n",
    "    if cur == -1: # Skip first line\n",
    "        cur += 1\n",
    "        continue\n",
    "    parts = line.split('\\t')\n",
    "    if cur < int(parts[1]):\n",
    "        all_X.append(parts[2])\n",
    "        all_y.append(int(parts[3]))\n",
    "        cur += 1\n",
    "\n",
    "# Split up 0-1: negative, 2(neutral) - skip, 3-4: positive\n",
    "all_X2 = []\n",
    "all_y2 = []\n",
    "all_bad = []\n",
    "all_good = []\n",
    "for i in range(len(all_X)):\n",
    "    if all_y[i] == 2:\n",
    "        continue\n",
    "    \n",
    "    new_y = -1 if all_y[i] < 2 else 1\n",
    "    \n",
    "    all_y2.append(new_y)\n",
    "    all_X2.append(all_X[i])\n",
    "    \n",
    "    if new_y == -1:\n",
    "        all_bad.append(all_X[i])\n",
    "    else:\n",
    "        all_good.append(all_X[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are examples of one negative and one positive movie review from the sample we just loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative:\n",
      "As inept as big-screen remakes of The Avengers and The Wild Wild West .\n",
      "\n",
      "Positive:\n",
      "Best indie of the year , so far .\n"
     ]
    }
   ],
   "source": [
    "# A bad example\n",
    "print \"Negative:\"\n",
    "print all_bad[8]\n",
    "print\n",
    "# A good one\n",
    "print \"Positive:\"\n",
    "print all_good[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to transform the movie review sentences into a format that the computer can understand and process efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In human: Demme finally succeeds in diminishing his stature from Oscar-winning master to lowly studio hack .\n",
      "In computer:   (0, 2467)\t1\n",
      "  (0, 2490)\t1\n",
      "  (0, 1136)\t1\n",
      "  (0, 1565)\t1\n",
      "  (0, 970)\t1\n",
      "  (0, 1771)\t1\n",
      "  (0, 2840)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vectorizer = CountVectorizer(min_df=5, stop_words='english', ngram_range=(1, 3))\n",
    "vX = vectorizer.fit_transform(all_X2)\n",
    "\n",
    "print \"In human:\", all_X2[763]\n",
    "print \"In computer:\", vX[763]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like a teacher gives you problems you've never seen before on a test, we want to save some movie reviews to test the classifier with after we train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(vX, all_y2, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to train the classifier. X_train is a list of movie reviews in \"computer language\" and y_train is a of \"good\" and \"bad labels\". We show the classifier both (with the fit) function and it learns the patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear', C=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well the classifier did: we show it movie reviews and it tells us what label it should have. The score shows what percent it got correct.  \"something about train and test data\"...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on examples used in training 93.4095860566 %\n",
      "Accuracy on new examples 73.9288307916 %\n"
     ]
    }
   ],
   "source": [
    "# How well we are doing:\n",
    "print \"Accuracy on examples used in training\", clf.score(X_train, y_train) * 100, \"%\"\n",
    "print \"Accuracy on new examples\", clf.score(X_test, y_test) * 100, \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may look like the computer did not do very well, but many sentences are confusing. Let's see how it does on specific examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1]\n",
      "[1]\n",
      "[-1]\n"
     ]
    }
   ],
   "source": [
    "# Let's look at some specific examples\n",
    "bad = [\"I have never seen a movie so dull and uninspired\"]\n",
    "textVX = vectorizer.transform(bad)\n",
    "print clf.predict(textVX)\n",
    "\n",
    "good = [\"What a masterpiece, everyone must see it\"]\n",
    "textVX = vectorizer.transform(good)\n",
    "print clf.predict(textVX)\n",
    "\n",
    "# User sentence\n",
    "good = [\"User sentence\"]\n",
    "textVX = vectorizer.transform(good)\n",
    "print clf.predict(textVX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What words would you use to tell apart good and bad movie reviews? (Boring, exhilarating...)\n",
    "Well, we can see what words computers identified as \"good-movie\" and \"bad-movie\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2.0590423049877331, u'eyes'),\n",
      " (1.9554853442935918, u'wonderful'),\n",
      " (1.7961338221794063, u'positive'),\n",
      " (1.7709577419185647, u'definitely'),\n",
      " (1.7502174415296463, u'solid'),\n",
      " (1.7384379821677389, u'foster'),\n",
      " (1.7132828813682044, u'fellow'),\n",
      " (1.6935165388934901, u'fluid'),\n",
      " (1.6358886173292073, u'remarkable'),\n",
      " (1.6297756510202248, u'assured')]\n"
     ]
    }
   ],
   "source": [
    "# What does it mean: -- try to do relative thing instead\n",
    "terms = [term for _, term in sorted((i, term) for term, i in vectorizer.vocabulary_.iteritems())]\n",
    "term_weights = sorted(zip(clf.coef_.toarray()[0], terms))\n",
    "from pprint import pprint\n",
    "\n",
    "# Top 100 terms:\n",
    "pprint(term_weights[-10:][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-1.8873532800634232, u'thinks'),\n",
      " (-1.790858856169399, u'worst'),\n",
      " (-1.7302709197129913, u'awful'),\n",
      " (-1.6920521360359153, u'lacking'),\n",
      " (-1.6544727648582032, u'busy'),\n",
      " (-1.6106764207496853, u'mess'),\n",
      " (-1.5884675903824927, u'poor'),\n",
      " (-1.5719907398966999, u'choices'),\n",
      " (-1.5687735907919551, u'problem'),\n",
      " (-1.5565110850977235, u'look like')]\n"
     ]
    }
   ],
   "source": [
    "pprint(term_weights[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some conclusion..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
