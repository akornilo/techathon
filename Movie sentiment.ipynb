{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Review Classification\n",
    "\n",
    "Here we show how a computer can tell apart good and bad movie reviews. To do so, we create a \"classifier\": A device that learns data categorization patterns from a \"labeled\" data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we get a lot of movie reviews and label them as good or bad. We will use these real reviews to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP MAGIC\n",
    "f = open(\"train.tsv\")\n",
    "cur = -1\n",
    "all_X = []\n",
    "all_y = []\n",
    "for line in f:\n",
    "    if cur == -1: # Skip first line\n",
    "        cur += 1\n",
    "        continue\n",
    "    parts = line.split('\\t')\n",
    "    if cur < int(parts[1]):\n",
    "        all_X.append(parts[2])\n",
    "        all_y.append(int(parts[3]))\n",
    "        cur += 1\n",
    "\n",
    "# Split up 0-1: negative, 2(neutral) - skip, 3-4: positive\n",
    "all_X2 = []\n",
    "all_y2 = []\n",
    "all_bad = []\n",
    "all_good = []\n",
    "for i in range(len(all_X)):\n",
    "    if all_y[i] == 2:\n",
    "        continue\n",
    "    \n",
    "    new_y = -1 if all_y[i] < 2 else 1\n",
    "    \n",
    "    all_y2.append(new_y)\n",
    "    all_X2.append(all_X[i])\n",
    "    \n",
    "    if new_y == -1:\n",
    "        all_bad.append(all_X[i])\n",
    "    else:\n",
    "        all_good.append(all_X[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are examples of one negative and one positive movie review from the sample we just loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative:\n",
      "As inept as big-screen remakes of The Avengers and The Wild Wild West .\n",
      "Positive:\n",
      "Robert Harmon 's less-is-more approach delivers real bump-in - the-night chills -- his greatest triumph is keeping the creepy crawlies hidden in the film 's thick shadows .\n"
     ]
    }
   ],
   "source": [
    "# A bad example\n",
    "print(\"Negative:\")\n",
    "print(all_bad[8])\n",
    "print\n",
    "# A good one\n",
    "print(\"Positive:\")\n",
    "print(all_good[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Training' the computer\n",
    "Now we have to transform the movie review sentences into a format that the computer can understand and process efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In human: Demme finally succeeds in diminishing his stature from Oscar-winning master to lowly studio hack .\n",
      "In computer:   (0, 2840)\t0.3680401183831172\n",
      "  (0, 1771)\t0.357838759868937\n",
      "  (0, 970)\t0.35556629724363537\n",
      "  (0, 1565)\t0.3626961808947826\n",
      "  (0, 1136)\t0.4295872245084288\n",
      "  (0, 2490)\t0.3739789902976097\n",
      "  (0, 2467)\t0.39257676087603205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=5, stop_words='english', max_df=0.9, lowercase=True, ngram_range=(1,3))\n",
    "vX = vectorizer.fit_transform(all_X2)\n",
    "\n",
    "print(\"In human:\", all_X2[763])\n",
    "print(\"In computer:\", vX[763])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like a teacher gives you problems you've never seen before on a test, we want to save some movie reviews to test the classifier with after we train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(vX, all_y2, test_size=0.2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to train the classifier. X_train is a list of movie reviews in \"computer language\" and y_train is a of \"good\" and \"bad labels\". We show the classifier both (with the fit) function and it learns the patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=200, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(max_iter=200)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well did we do?\n",
    "Let's see how well the classifier did: we show it movie reviews and it tells us what label it should have. The score shows what percent it got correct.  \"something about train and test data\"...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on examples used in training 90.64996368917939 %\n",
      "Accuracy on new examples 76.6158315177923 %\n"
     ]
    }
   ],
   "source": [
    "# How well we are doing:\n",
    "print(\"Accuracy on examples used in training\", clf.score(X_train, y_train) * 100, \"%\")\n",
    "print(\"Accuracy on new examples\", clf.score(X_test, y_test) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may look like the computer did not do very well, but many sentences are confusing. Let's see how it does on specific examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explainer(sent, tv, clf):\n",
    "    id_map = {v:k for k,v in tv.vocabulary_.items()}\n",
    "    vec = tv.transform([sent]).nonzero()[1]\n",
    "    score = clf.decision_function(tv.transform([sent]))[0]\n",
    "    \n",
    "    if score < -1.:\n",
    "        print(\"This movie is bad\")\n",
    "    elif score > 0.5:\n",
    "        print(\"I think its good\")\n",
    "    else:\n",
    "        print(\"I am not sure\")\n",
    "        \n",
    "    print(\"Let me tell you why:\")\n",
    "    print(\"\")\n",
    "    for word in vec:\n",
    "        print(id_map[word], \"is\", round(clf.coef_[0, word] * tv.idf_[word], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer(all_good[10], vectorizer, clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE MAGIC COMPUTER MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have never seen a movie so dull and uninspired\n",
      "This movie is bad\n",
      "Let me tell you why:\n",
      "\n",
      "uninspired is -8.9\n",
      "seen is 0.0\n",
      "movie is -2.6\n",
      "dull is -13.5\n",
      "\n",
      "\n",
      "What a masterpiece, everyone must see it\n",
      "I think its good\n",
      "Let me tell you why:\n",
      "\n",
      "masterpiece is 11.0\n"
     ]
    }
   ],
   "source": [
    "# Let's look at some specific examples\n",
    "bad = \"I have never seen a movie so dull and uninspired\"\n",
    "print(\"I have never seen a movie so dull and uninspired\")\n",
    "explainer(bad, vectorizer, clf)\n",
    "\n",
    "print()\n",
    "print()\n",
    "good = \"What a masterpiece, everyone must see it\"\n",
    "print(\"What a masterpiece, everyone must see it\")\n",
    "explainer(good, vectorizer, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hate this actor\n",
      "I am not sure\n",
      "Let me tell you why:\n",
      "\n",
      "hate is -6.9\n",
      "actor is 5.6\n"
     ]
    }
   ],
   "source": [
    "# User sentence\n",
    "user_sentence = \"I hate this actor\"\n",
    "textVX = vectorizer.transform([user_sentence])\n",
    "print(user_sentence)\n",
    "explainer(user_sentence, vectorizer, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm does poorly on the confusing sentence, because it does not consider the word order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Although the plot was poor, the execution was good\n",
      "This movie is bad\n",
      "Let me tell you why:\n",
      "\n",
      "poor is -7.5\n",
      "plot is -7.2\n",
      "good is 4.2\n",
      "execution is -8.2\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "good = \"Although the plot was poor, the execution was good\"\n",
    "print(\"Although the plot was poor, the execution was good\")\n",
    "explainer(good, vectorizer, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underlying mechanism\n",
    "What words would you use to tell apart good and bad movie reviews? (Boring, exhilarating...)\n",
    "Well, we can see what words computers identified as \"good-movie\" and \"bad-movie\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does it mean: -- try to do relative thing instead\n",
    "terms = [term for _, term in sorted((i, term) for term, i in vectorizer.vocabulary_.iteritems())]\n",
    "term_weights = sorted(zip(clf.coef_.toarray()[0], terms))\n",
    "from pprint import pprint\n",
    "\n",
    "# Top 100 terms:\n",
    "pprint(term_weights[-10:][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(term_weights[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "nterms = 25\n",
    "randpoints = np.random.choice(len(terms), [1, nterms])[0]\n",
    "randweights = clf.coef_.toarray()[0][randpoints]\n",
    "randterms = np.array(terms)[randpoints]\n",
    "plt.plot(randweights, np.arange(0, nterms), '+')\n",
    "plt.yticks([])\n",
    "plt.title('Term weights')\n",
    "plt.xlabel('Positivity weight')\n",
    "for i in xrange(nterms):\n",
    "    plt.text(randweights[i] + 0.05, i - 0.15, randterms[i], size='smaller')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Takeaways\n",
    "\n",
    "- Using basic Machine Learning techniques, we were able to correctly predict the sentiment/rating of 3 out of 4 movie reviews.\n",
    "- The algorithm was able to identify clearly \"good\" (hilarious, masterpiece) and \"bad\" (worst, stupid) words, and use them to guess the rating.\n",
    "- The algorithm was confused by words that contained both good and bad words.\n",
    "    - This happened because the algorithm looked only at individual words, not at how they were connected by words like 'although' and 'but'\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
