{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Review Classification\n",
    "\n",
    "Here we show how a computer can tell apart good and bad movie reviews. To do so, we create a \"classifier\": A device that learns data categorization patterns from a \"labeled\" data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we get a lot of movie reviews and label them as good or bad. We will use these real reviews to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SETUP MAGIC\n",
    "f = open(\"train.tsv\")\n",
    "cur = -1\n",
    "all_X = []\n",
    "all_y = []\n",
    "for line in f:\n",
    "    if cur == -1: # Skip first line\n",
    "        cur += 1\n",
    "        continue\n",
    "    parts = line.split('\\t')\n",
    "    if cur < int(parts[1]):\n",
    "        all_X.append(parts[2])\n",
    "        all_y.append(int(parts[3]))\n",
    "        cur += 1\n",
    "\n",
    "# Split up 0-1: negative, 2(neutral) - skip, 3-4: positive\n",
    "all_X2 = []\n",
    "all_y2 = []\n",
    "all_bad = []\n",
    "all_good = []\n",
    "for i in range(len(all_X)):\n",
    "    if all_y[i] == 2:\n",
    "        continue\n",
    "    \n",
    "    new_y = -1 if all_y[i] < 2 else 1\n",
    "    \n",
    "    all_y2.append(new_y)\n",
    "    all_X2.append(all_X[i])\n",
    "    \n",
    "    if new_y == -1:\n",
    "        all_bad.append(all_X[i])\n",
    "    else:\n",
    "        all_good.append(all_X[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are examples of one negative and one positive movie review from the sample we just loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A bad example\n",
    "print \"Negative:\"\n",
    "print all_bad[8]\n",
    "print\n",
    "# A good one\n",
    "print \"Positive:\"\n",
    "print all_good[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Training' the computer\n",
    "Now we have to transform the movie review sentences into a format that the computer can understand and process efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vectorizer = CountVectorizer(min_df=5, stop_words='english')\n",
    "vX = vectorizer.fit_transform(all_X2)\n",
    "\n",
    "print \"In human:\", all_X2[763]\n",
    "print \"In computer:\", vX[763]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like a teacher gives you problems you've never seen before on a test, we want to save some movie reviews to test the classifier with after we train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(vX, all_y2, test_size=0.2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to train the classifier. X_train is a list of movie reviews in \"computer language\" and y_train is a of \"good\" and \"bad labels\". We show the classifier both (with the fit) function and it learns the patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear', C=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well did we do?\n",
    "Let's see how well the classifier did: we show it movie reviews and it tells us what label it should have. The score shows what percent it got correct.  \"something about train and test data\"...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How well we are doing:\n",
    "print \"Accuracy on examples used in training\", clf.score(X_train, y_train) * 100, \"%\"\n",
    "print \"Accuracy on new examples\", clf.score(X_test, y_test) * 100, \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may look like the computer did not do very well, but many sentences are confusing. Let's see how it does on specific examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's look at some specific examples\n",
    "bad = [\"I have never seen a movie so dull and uninspired\"]\n",
    "textVX = vectorizer.transform(bad)\n",
    "print \"I have never seen a movie so dull and uninspired\"\n",
    "print \"Prediction:\", clf.predict(textVX)\n",
    "\n",
    "good = [\"What a masterpiece, everyone must see it\"]\n",
    "textVX = vectorizer.transform(good)\n",
    "print \"What a masterpiece, everyone must see it\"\n",
    "print \"Prediction:\", clf.predict(textVX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# User sentence\n",
    "user_sentence = \"\"\n",
    "textVX = vectorizer.transform([user_sentence])\n",
    "print user_sentence\n",
    "print clf.predict(textVX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm does poorly on the confusing sentence, because it does not consider the word order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusing = [\"Although the plot was good, the execution was poor\"]\n",
    "textVX = vectorizer.transform(good)\n",
    "print \"Although the plot had potential, the execution was poor\"\n",
    "print clf.predict(textVX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusing = [\"Although the plot was poor, the execution was good\"]\n",
    "textVX = vectorizer.transform(good)\n",
    "print \"Although the plot was poor, the execution was good\"\n",
    "print clf.predict(textVX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusing = [\"plot Although the execution good poor the was was\"]\n",
    "textVX = vectorizer.transform(good)\n",
    "print \"plot Although the execution good poor the was was\"\n",
    "print clf.predict(textVX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underlying mechanism\n",
    "What words would you use to tell apart good and bad movie reviews? (Boring, exhilarating...)\n",
    "Well, we can see what words computers identified as \"good-movie\" and \"bad-movie\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What does it mean: -- try to do relative thing instead\n",
    "terms = [term for _, term in sorted((i, term) for term, i in vectorizer.vocabulary_.iteritems())]\n",
    "term_weights = sorted(zip(clf.coef_.toarray()[0], terms))\n",
    "from pprint import pprint\n",
    "\n",
    "# Top 100 terms:\n",
    "pprint(term_weights[-10:][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pprint(term_weights[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "nterms = 25\n",
    "randpoints = np.random.choice(len(terms), [1, nterms])[0]\n",
    "randweights = clf.coef_.toarray()[0][randpoints]\n",
    "randterms = np.array(terms)[randpoints]\n",
    "plt.plot(randweights, np.arange(0, nterms), '+')\n",
    "plt.yticks([])\n",
    "plt.title('Term weights')\n",
    "plt.xlabel('Positivity weight')\n",
    "for i in xrange(nterms):\n",
    "    plt.text(randweights[i] + 0.05, i - 0.15, randterms[i], size='smaller')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Takeaways\n",
    "\n",
    "- Using basic Machine Learning techniques, we were able to correctly predict the sentiment/rating of 3 out of 4 movie reviews.\n",
    "- The algorithm was able to identify clearly \"good\" (hilarious, masterpiece) and \"bad\" (worst, stupid) words, and use them to guess the rating.\n",
    "- The algorithm was confused by words that contained both good and bad words.\n",
    "    - This happened because the algorithm looked only at individual words, not at how they were connected by words like 'although' and 'but'\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
